from langchain.prompts import PromptTemplate
from langchain.llms.ctransformers import CTransformers

class BlogLLAMAHandler:
    """
    Handler to generate blog from LLAMA-2.
    """
    def __init__(self, model_path: str) -> None:
        self.llm = CTransformers(model=model_path,
                                 model_type="llama",
                                 config={"max_new_tokens": 256, "temperature": 0.01, })
        template = \
        """
        Write a blog for {blog_style} about {topic} with {num_words} words.
        """
        self.prompt = PromptTemplate(input_variables=["topic", "n_words", "blog_style"],
                                     template=template)


    def get_llm_response(self, topic: str, num_words: int, blog_style: str) -> str:
        """
        Get response from LLAMA-2.

        Args
        ----
            topic: str
                Input topic to LLAMA-2
            num_words: int
                Number of words in blog
            blog_style: str
                Style of output blog

        Returns
        -------
            str:
                Blog generated by LLM.

        """
        response = self.llm.invoke(self.prompt.format(topic=topic, num_words=num_words, blog_style=blog_style))
        return response